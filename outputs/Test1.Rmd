---
title: "NBA Project"
author: "Ilya Kukovitskiy"
date: "May 7, 2018"
output: html_document
self_contained: no
---
```{r,results='hide',message=FALSE}
set.seed(1)
library(tree)
library(randomForest)
library(gbm)
library(ggplot2)
```

## Data Preprocessing

Reading in and storing dataset from file
```{r}
d <- read.csv("nbasample2GrpPlus0429.csv",header=T, sep=",")
```

Removing ax_ and la_ variales, as requested
```{r}
a <- colnames(d)
AX <- grepl("ax_",a) #seeing which values have prefix ax_
AXN <- c() #creating temporary vector recording positions
for(i in 1:length(a)){ #getting rejected values
  if(AX[i]){
    AXN <- c(AXN,i)
  }
}
d <- d[,-AXN] #removing rejected values
a <- colnames(d)
LA <- grepl("la_",a)
LAN <- c() #creating temporary vector recording positions
for(i in 1:length(a)){ #getting rejected values
  if(LA[i]){
    LAN <- c(LAN,i)
  }
}
d <- d[,-LAN] #removing rejected values
a <- colnames(d)
#Cleaning up Environment
rm(AX,AXN,LA,LAN)
```

Removing other Variables
```{r}
#closest_arena and closest_team are identical - removing closest_arena
x <- match("closest_arena",a)
#x
d <- d[,-x]
a <- colnames(d)
#match("closest_arena",a) #successfully removed

#names(Filter(is.factor, d)) #taking a look at which variables have factors - tree() can only handle 32 levels on factor predictors

#zip_team and zip_arena have 56 levels - too many to grow trees on - removing both
x <- match(c("zip_team","zip_arena"),a)
#x
d <- d[,-x]
a <- colnames(d)
#match(c("zip_team","zip_arena"),a) #successfully removed
#email_domain has 1468 levels - too many.. -removing
x <- match(c("email_domain"),a)
#x
d <- d[,-x]
a <- colnames(d)
#match(c("email_domain"),a) #successfully removed
#source_date has 3773 levels - too many.. -removing
x <- match(c("source_date"),a)
#x
d <- d[,-x]
a <- colnames(d)
#match(c("source_date"),a) #successfully removed
```

**Making a training/test set vector**

```{r}
train <- sample(1:nrow(d), nrow(d)*(.8))
```


**Viewing Response Variables**

```{r}
POST <- grepl("post_",a)
POSTN <- c()
for(i in 1:length(a)){ #getting rejected values
  if(POST[i]){
    POSTN <- c(POSTN,i)
  }
}
#POSTN
a[POSTN]
```

## <a id="top"></a>Given this dataset, a few useful questions can be answered:

### [**A** - Who buys tickets?](#begin_A)
#### Successful or unsuccessful marketting strategies can be identified.
##### [Model A Assessment](#end_A)
### [**B** - How many tickets do people buy?](#begin_B)
#### Besides success of strategy; if a person is likely to buy more tickets than they have purchased, they can likely be sold more tickets.
##### [Model B Assessment](#end_B)

### [**C** - How much money do people spend on tickets?](#begin_C)
#### Same rationale as B, but with dollar-value rather than number of games.
##### [Model C Assessment](#end_C)

### [**D** - Who buys tickets at which price?](#begin_D)
#### Better seats can be marketted more to those who are more likely to buy them.
##### [Model D Assessment](#end_D)


### <a id="begin_A"></a>A - Who buys tickets?

Creating matrix to record model type and effectiveness
```{r}
A_methods <- matrix(c("",""),
                    nrow=1,
                    ncol=2)
colnames(A_methods) <- c("Method","Accuracy")
```

Removing other response variables besides post_tickets_flag
```{r}
Q <- match('post_tickets_flag',a)
a[Q]
POSTN_ptf <- POSTN[! POSTN %in% Q]
#POSTN_ptf
a[POSTN_ptf]
dataset.ptf <- d[,-POSTN_ptf]
```
```{r,results='hide',message=FALSE}
attach(dataset.ptf)
```

**Growing Trees**
Creating pure Classification Response Vector
```{r}
#Finding response vector
a.ptf <- colnames(dataset.ptf)
resp.ptf <- grepl("post_",a.ptf)
for(i in 1:length(a.ptf)){
  if(resp.ptf[i]){
    R <- i
  }
}
a.ptf[R]
#Converting it to a yes/no factor
y <- post_tickets_flag
Ticket <- ifelse(y<0.5,"No","Yes")
dataset.ptf[,R] <- Ticket
dataset.ptf[,R] <- factor(dataset.ptf[,R])
```
```{r,results='hide',message=FALSE}
attach(dataset.ptf)
```
```{r}
#Cleaning up environment space (keeping y as is for creaing boosted tree)
rm(Ticket) 
```

Growing Preliminary Classification Tree
```{r}
#Growing Tree
tree.ptf <- tree(post_tickets_flag~., dataset.ptf)
#Plotting Tree
plot(tree.ptf)
text(tree.ptf,pretty=0)
```

Estimate and Record Error Rate on (extremely similar) Trained Tree
```{r}
#Growing Tree
tree.ptf_train <- tree(post_tickets_flag~., dataset.ptf, subset=train)
#Plotting Tree
plot(tree.ptf_train)
text(tree.ptf_train,pretty=0)
#Fitting model on test set
tree.ptf_pred <- predict(tree.ptf_train, dataset.ptf[-train,], type="class")
#Confusion Matrix
M <- table(tree.ptf_pred, post_tickets_flag[-train])
M
A_methods <- rbind(A_methods, c("Tree",(1-(M[1,2]+M[2,1])/(sum(M)))))
```
```{r,echo=FALSE}
print(paste("The test error rate is", ((M[1,2]+M[2,1])/(sum(M)))))
```

Pruning the Tree
```{r}
#Cross Validating Tree
cv.ptf_train <- cv.tree(tree.ptf_train, FUN=prune.misclass)
#Looking for best parameter
cv.ptf_train
b <- which.min(cv.ptf_train$dev)
Best <- cv.ptf_train$size[b]
```
```{r,echo=FALSE}
print(paste("The best trees seem to be of size",cv.ptf_train$size[b],"with cross-validation error of",cv.ptf_train$dev[b]))
```
```{r}
#Pruning tree according to this
prune.ptf_train <- prune.misclass(tree.ptf_train, best=Best)
#Plotting Tree
plot(prune.ptf_train)
text(prune.ptf_train,pretty=0)
#Fitting model on test set
prune.ptf_pred <- predict(prune.ptf_train, dataset.ptf[-train,], type="class")
#Confusion Matrix
M_prune <- table(prune.ptf_pred, post_tickets_flag[-train])
M_prune
A_methods <- rbind(A_methods, c('Cross Validated Tree',(1-(M_prune[1,2]+M_prune[2,1])/(sum(M_prune)))))
```
```{r,echo=FALSE}
print(paste("The test error rate is", ((M_prune[1,2]+M_prune[2,1])/(sum(M_prune)))))
print("Same error rate.")
```

#### <a id="end_A"></a>Looking at Most Effective Method
```{r}
A_methods <- A_methods[-1,]
A_methods[order(A_methods[,2],decreasing = TRUE),]
Top <- A_methods[1,]
```
```{r,echo=FALSE}
print(paste("The most effective method was the",Top[1],", with",Top[2],"accuracy."))
A_methods <- matrix(c("",""),
                    nrow=1,
                    ncol=2)
```
[Back to top](#top)

### <a id="begin_B"></a>B - How many tickets do people buy?

Removing other response variables besides post_total_tickets
```{r}
Q <- match('post_total_tickets',a)
a[Q]
POSTN_ptt <- POSTN[! POSTN %in% Q]
#POSTN_ptt
a[POSTN_ptt]
dataset.ptt <- d[,-POSTN_ptt]
```
```{r,results='hide',message=FALSE}
attach(dataset.ptt)
```

Looking at distribution of test response variable
```{r}
#Creating Violin Plot
p <- ggplot(dataset.ptt[-train,], aes(y=post_total_tickets, 1))
p + geom_violin()
#Finding Number of Zeroes
O <- table(post_total_tickets[-train]==0)
#O[2]
```
```{r,echo=FALSE}
print(paste(O[2]/(O[1]+O[2]),"of the values are zeroes."))
```

