---
title: "NBA Project"
author: "Ilya Kukovitskiy"
date: "May 7, 2018"
output: html_document
self_contained: no
---
```{r,results='hide',message=FALSE}
set.seed(1)
library(tree)
library(randomForest)
library(gbm)
library(ggplot2)
```

## Data Preprocessing

#### Reading in and storing dataset from file

```{r}
d <- read.csv("nbasample2GrpPlus0429.csv",header=T, sep=",")
```

#### Removing ax_ and la_ variales, as requested

```{r}
a <- colnames(d)
AX <- grepl("ax_",a) #seeing which values have prefix ax_
AXN <- c() #creating temporary vector recording positions
for(i in 1:length(a)){ #getting rejected values
  if(AX[i]){
    AXN <- c(AXN,i)
  }
}
d <- d[,-AXN] #removing rejected values
a <- colnames(d)
LA <- grepl("la_",a)
LAN <- c() #creating temporary vector recording positions
for(i in 1:length(a)){ #getting rejected values
  if(LA[i]){
    LAN <- c(LAN,i)
  }
}
d <- d[,-LAN] #removing rejected values
a <- colnames(d)
#Cleaning up Environment
rm(AX,AXN,LA,LAN)
```

#### Removing other Variables

```{r}
#closest_arena and closest_team are identical - removing closest_arena

x <- match("closest_arena",a)
#x
d <- d[,-x]
a <- colnames(d)
#match("closest_arena",a) #successfully removed

#tree() can only handle 32 levels on factor predictors

#names(Filter(is.factor, d)) #taking a look at which variables have factors - 

#zip_team and zip_arena have 56 levels - too many to grow trees on - removing both
x <- match(c("zip_team","zip_arena"),a)
#x
d <- d[,-x]
a <- colnames(d)
#match(c("zip_team","zip_arena"),a) #successfully removed

#email_domain has 1468 levels - too many.. -removing
x <- match(c("email_domain"),a)
#x
d <- d[,-x]
a <- colnames(d)
#match(c("email_domain"),a) #successfully removed

#source_date has 3773 levels - too many.. -removing
x <- match(c("source_date"),a)
#x
d <- d[,-x]
a <- colnames(d)
#match(c("source_date"),a) #successfully removed
```

#### Making a training/test set vector

```{r}
train <- sample(1:nrow(d), nrow(d)*(.8))
```

#### Viewing Response Variables

```{r}
POST <- grepl("post_",a)
POSTN <- c()
for(i in 1:length(a)){ #getting rejected values
  if(POST[i]){
    POSTN <- c(POSTN,i)
  }
}
#POSTN
a[POSTN]
```

## <a id="top"></a>Given this dataset, a few useful questions can be answered:

### [**A** - Who buys tickets?](#begin_A)
#### Successful or unsuccessful marketting strategies can be identified.
##### [Model A Assessment](#end_A)
### [**B** - How many tickets do people buy?](#begin_B)
#### Besides success of strategy; if a person is likely to buy more tickets than they have purchased, they can likely be sold more tickets.
##### [Model B Assessment](#end_B)

### [**C** - How much money do people spend on tickets?](#begin_C)
#### Same rationale as B, but with dollar-value rather than number of games.
##### [Model C Assessment](#end_C)

### [**D** - Who buys tickets at which price?](#begin_D)
#### Better seats can be marketted more to those who are more likely to buy them.
##### [Model D Assessment](#end_D)


## <a id="begin_A"></a>A - Who buys tickets?

## Creating matrix to record model type and effectiveness

```{r}
A_methods <- matrix(c("",""),
                    nrow=1,
                    ncol=2)
colnames(A_methods) <- c("Method","Accuracy")
```

### Removing other response variables besides post_tickets_flag

```{r}
#Finding position of response variable
Q <- match('post_tickets_flag',a)
a[Q]
#Finding position of all other response (post_) variables
POSTN_ptf <- POSTN[! POSTN %in% Q]
#POSTN_ptf
a[POSTN_ptf]
dataset.ptf <- d[,-POSTN_ptf]
```
```{r,results='hide',message=FALSE}
attach(dataset.ptf)
```

#### Creating pure Classification Response Vector

```{r}
#Finding response vector
a.ptf <- colnames(dataset.ptf)
resp.ptf <- grepl("post_",a.ptf)
for(i in 1:length(a.ptf)){
  if(resp.ptf[i]){
    R <- i
  }
}
a.ptf[R]
#Converting it to a yes/no factor
y <- post_tickets_flag
Ticket <- ifelse(y<0.5,"No","Yes")
dataset.ptf[,R] <- Ticket
dataset.ptf[,R] <- factor(dataset.ptf[,R])
```
```{r,results='hide',message=FALSE}
attach(dataset.ptf)
```
```{r}
#Cleaning up environment space (keeping y as is for creaing boosted tree)
rm(Ticket) 
```

#### Growing Preliminary Classification Tree

```{r}
#Growing Tree
tree.ptf <- tree(post_tickets_flag~., dataset.ptf)
#Plotting Tree
plot(tree.ptf)
text(tree.ptf,pretty=0)
```

#### Growing (extremely similar) Trained Tree

```{r}
#Growing Tree
tree.ptf_train <- tree(post_tickets_flag~., dataset.ptf, subset=train)
#Plotting Tree
plot(tree.ptf_train)
text(tree.ptf_train,pretty=0)
```

#### Estimating and Record Error Rate

```{r}
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
tree.ptf_pred <- predict(tree.ptf_train, dataset.ptf[-train,], type="class")
#Confusion Matrix
M <- table(tree.ptf_pred, post_tickets_flag[-train])
M
A_methods <- rbind(A_methods, c("Tree",(1-(M[1,2]+M[2,1])/(sum(M)))))
```
```{r,echo=FALSE}
print(paste("The test error rate is", ((M[1,2]+M[2,1])/(sum(M)))))
#MSE
#Cross Validating Tree
cv.ptf_train <- cv.tree(tree.ptf_train, FUN=prune.misclass)
#Looking for best parameter
cv.ptf_train
b <- which.min(cv.ptf_train$dev)
Best <- cv.ptf_train$size[b]
```
```{r,echo=FALSE}
print(paste("The best trees seem to be of size",cv.ptf_train$size[b],"with cross-validation error of",cv.ptf_train$dev[b]))
```
```{r}
#Pruning tree according to this
prune.ptf_train <- prune.misclass(tree.ptf_train, best=Best)
#Plotting Tree
plot(prune.ptf_train)
text(prune.ptf_train,pretty=0)
```

#### Estimating and Record Error Rate

```{r}
#Fitting model on test set
prune.ptf_pred <- predict(prune.ptf_train, dataset.ptf[-train,], type="class")
#Confusion Matrix
M_prune <- table(prune.ptf_pred, post_tickets_flag[-train])
M_prune
A_methods <- rbind(A_methods, c('Cross Validated Tree',(1-(M_prune[1,2]+M_prune[2,1])/(sum(M_prune)))))
```
```{r,echo=FALSE}
print(paste("The test error rate is", ((M_prune[1,2]+M_prune[2,1])/(sum(M_prune)))))
print("Same error rate.")
```

#### Creating Bagged Tree

```{r}
#Creating a modified dataset - na values are not accepted in bagged trees
dataset.ptf0 <- dataset.ptf
dataset.ptf0[is.na(dataset.ptf0)] <- 0
```
```{r,results='hide',message=FALSE}
attach(dataset.ptf0)
```
```{r}
#Growing Tree
bag.ptf_train <- randomForest(post_tickets_flag~., data=dataset.ptf0, subset=train, mtry=ncol(dataset.ptf0)-1, ntrees=1000, importance=TRUE)
#Can't plot tree
#Fitting tree on test set
bag.ptf_pred <- predict(bag.ptf_train, dataset.ptf0[-train,], type="class")
#Confusion Matrix
M_bag <- table(bag.ptf_pred, post_tickets_flag[-train])
M_bag
A_methods <- rbind(A_methods, c('Bagged Tree',(1-(M_bag[1,2]+M_bag[2,1])/(sum(M_bag)))))
```
```{r,echo=FALSE}
print(paste("The test error rate is", ((M_bag[1,2]+M_bag[2,1])/(sum(M_bag)))))
print("About 90% accurate!")
```

#### Looking at Predictor Importance 

```{r}
bag.I <- importance(bag.ptf_train)
bag.I <- bag.I[ order(bag.I[,3],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by error) according to this model are as follows:")
```
```{r}
bag.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
bag.I <- bag.I[ order(bag.I[,4],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by Gini index) according to this model are as follows:")
```
```{r}
bag.I[1:15,] 
```

#### Creating Random Forest Tree

```{r}
#Growing Tree
RF.ptf_train <- randomForest(post_tickets_flag~., data=dataset.ptf0, subset=train, ntrees=1000, importance=TRUE)
#Can't plot tree
```

#### Estimating and Record Error Rate

```{r}
#Fitting model on test set
RF.ptf_pred <- predict(RF.ptf_train, dataset.ptf0[-train,], type="class")
#Confusion Matrix
M_RF <- table(RF.ptf_pred, post_tickets_flag[-train])
M_RF
A_methods <- rbind(A_methods, c('Random Forest Tree',(1-(M_RF[1,2]+M_bag[2,1])/(sum(M_RF)))))
```
```{r,echo=FALSE}
print(paste("The test error rate is", ((M_RF[1,2]+M_bag[2,1])/(sum(M_RF)))))
print("More than 90% accurate!")
```

#### Looking at Predictor Importance

```{r}
RF.I <- importance(RF.ptf_train)
RF.I <- RF.I[ order(RF.I[,3],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by error) according to this model are as follows:")
```
```{r}
RF.I[1:15,] 
RF.I <- RF.I[ order(RF.I[,4],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by Gini index) according to this model are as follows:")
```
```{r}
RF.I[1:15,] 
```

#### Creating a Boosted Tree

```{r}
#Creating a modified dataset - columns with no variation are not accepted in boosted trees
dataset.ptfB <- dataset.ptf
colnames(dataset.ptfB)[c(36,56)]
dataset.ptfB <- dataset.ptfB[,-c(36,56)]
```
```{r,results='hide',message=FALSE}
attach(dataset.ptfB)
```
```{r}
#Modify response variable
dataset.ptfB$post_tickets_flag <- y
#distribution='bernoulli' requires 0,1 variable
#Growing Tree
boost.ptf_train <- gbm(post_tickets_flag~., data=dataset.ptfB[train,], distribution='bernoulli', n.trees=1000, interaction.depth=4)
#Can't plot tree
```

#### Estimating and Record Error Rate

```{r}
#Fitting model on test set
boost.ptf_pred <- predict(boost.ptf_train, dataset.ptfB[-train,], n.trees=1000)
#Confusion Matrix
M_boost <- table(boost.ptf_pred, post_tickets_flag[-train])
A_methods <- rbind(A_methods, c('Boosted Tree',(1-(M_boost[1,2]+M_boost[2,1])/(sum(M_boost)))))
```
```{r,echo=FALSE}
print(paste("The test error rate is", ((M_boost[1,2]+M_boost[2,1])/(sum(M_boost)))))
print("A bit worse, but still above 90% accuracy!")
```

### <a id="end_A"></a>**A** Looking at Most Effective Method

```{r}
A_methods <- A_methods[-1,]
A_methods[order(A_methods[,2],decreasing = TRUE),]
Top <- A_methods[1,]
```
```{r,echo=FALSE}
print(paste("The most effective method was the",Top[1],", with",Top[2],"accuracy."))
A_methods <- matrix(c("",""),
                    nrow=1,
                    ncol=2)
```

[Back to top](#top)

## <a id="begin_B"></a>B - How many tickets do people buy?

### Removing other response variables besides post_total_tickets

```{r}
#Finding postion of desired response variable
Q <- match('post_total_tickets',a)
a[Q]
#Removing all other response (post_) variables
POSTN_ptt <- POSTN[! POSTN %in% Q]
#POSTN_ptt
a[POSTN_ptt]
dataset.ptt <- d[,-POSTN_ptt]
```
```{r,results='hide',message=FALSE}
attach(dataset.ptt)
```

#### Looking at distribution of test response variable

```{r}
#Creating Violin Plot
p <- ggplot(dataset.ptt[-train,], aes(y=post_total_tickets, 1))
p + geom_violin()
```

#### That's a lot of zeroes

```{r}
#Finding Number of Zeroes
O <- table(post_total_tickets[-train]==0)
#O[2]
```

#### Growing Preliminary Regression Tree

```{r}
#Growing Tree
tree.ptt <- tree(post_total_tickets~., dataset.ptt)
#Plotting Tree
plot(tree.ptt)
text(tree.ptt,pretty=0)
```

#### Estimate MSE on (extremely similar) Trained Tree

```{r}
#Growing Tree
tree.ptt_train <- tree(post_total_tickets~., dataset.ptt, subset=train)
#Plotting Tree
plot(tree.ptt_train)
text(tree.ptt_train,pretty=0)
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
tree.ptt_pred <- predict(tree.ptt_train, dataset.ptt[-train,])
plot(tree.ptt_pred, post_total_tickets[-train])
abline(0,1)
#MSE
MSE.ptt <- mean((tree.ptt_pred-post_total_tickets[-train])^2)
MSE.ptt
A_methods <- rbind(A_methods, c('Tree',MSE.ptt))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.ptt,". Root MSE is",sqrt(MSE.ptt),", indicating this model leads to test predictions within around",round(sqrt(MSE.ptt),2),"total tickets purchased."))
#fix Compare with distribution of response through box-plot
```

Pruning the Tree
```{r}
#Cross Validating Tree
cv.ptt_train <- cv.tree(tree.ptt_train, FUN=prune.tree)
#Finding best paramater to prune
cv.ptt_train
b <- which.min(cv.ptt_train$dev)
Best <- cv.ptt_train$size[b]
```
```{r,echo=FALSE}
print(paste("The best trees seem to be of size",cv.ptt_train$size[b],"with deviation of",cv.ptt_train$dev[b],"."))
```
```{r}
#Pruning Tree according to this
prune.ptt_train <- prune.tree(tree.ptt_train, best=Best)
#Plotting Tree
plot(prune.ptt_train)
text(prune.ptt_train,pretty=0)
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
prune.ptt_pred <- predict(prune.ptt_train, dataset.ptt[-train,])
plot(prune.ptt_pred, post_total_tickets[-train])
abline(0,1)
#MSE
MSE.prune.ptt <- mean((prune.ptt_pred-post_total_tickets[-train])^2)
MSE.prune.ptt
A_methods <- rbind(A_methods, c('Cross Validated Tree',MSE.prune.ptt))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.prune.ptt,". Root MSE is",sqrt(MSE.prune.ptt),", indicating this model leads to test predictions within around",round(sqrt(MSE.prune.ptt),2),"total tickets purchased."))
```

#### Creating Bagged Tree

```{r}
#Creating a modified dataset - na values are not accepted in bagged trees
dataset.ptt0 <- dataset.ptt
dataset.ptt0[is.na(dataset.ptt0)] <- 0
```
```{r,results='hide',message=FALSE}
attach(dataset.ptt0)
```
```{r}
#Growing Tree
bag.ptt_train <- randomForest(post_total_tickets~., data=dataset.ptt0, subset=train, mtry=ncol(dataset.ptt0)-1, ntrees=1000, importance=TRUE)
#Can't plot tree
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
bag.ptt_pred <- predict(bag.ptt_train, dataset.ptt0[-train,])
plot(bag.ptt_pred, post_total_tickets[-train])
abline(0,1)
#MSE
MSE.bag.ptt <- mean((bag.ptt_pred-post_total_tickets[-train])^2)
MSE.bag.ptt
A_methods <- rbind(A_methods, c('Bagged Tree',MSE.bag.ptt))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.bag.ptt,". Root MSE is",sqrt(MSE.bag.ptt),", indicating this model leads to test predictions within around",round(sqrt(MSE.bag.ptt),2),"total tickets purchased."))
```

#### Looking at Predictor Importance 

```{r}
bag.I <- importance(bag.ptf_train)
bag.I <- bag.I[ order(bag.I[,3],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by error) according to this model are as follows:")
```
```{r}
bag.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
bag.I <- bag.I[ order(bag.I[,4],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by Gini index) according to this model are as follows:")
```
```{r}
bag.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
```

#### Creating Random Forest Tree

```{r}
#Growing Tree
RF.ptt_train <- randomForest(post_total_tickets~., data=dataset.ptt0, subset=train, importance=TRUE)
#Can't plot tree
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
RF.ptt_pred <- predict(RF.ptt_train, dataset.ptt0[-train,])
plot(RF.ptt_pred, post_total_tickets[-train])
abline(0,1)
#MSE
MSE.RF.ptt <- mean((RF.ptt_pred-post_total_tickets[-train])^2)
MSE.RF.ptt
A_methods <- rbind(A_methods, c('Random Forest Tree',MSE.RF.ptt))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.bag.ptt,". Root MSE is",sqrt(MSE.RF.ptt),", indicating this model leads to test predictions within around",round(sqrt(MSE.RF.ptt),2),"total tickets purchased."))
```

#### Looking at Predictor Importance 

```{r}
RF.I <- importance(RF.ptf_train)
RF.I <- RF.I[ order(RF.I[,3],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by error) according to this model are as follows:")
```
```{r}
RF.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
RF.I <- RF.I[ order(RF.I[,4],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by Gini index) according to this model are as follows:")
```
```{r}
RF.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
```

#### Creating a Boosted Tree

```{r}
#Creating a modified dataset - columns with no variation are not accepted in boosted trees
dataset.pttB <- dataset.ptt
colnames(dataset.pttB)[c(36,56)]
dataset.pttB <- dataset.pttB[,-c(36,56)]
```
```{r,results='hide',message=FALSE}
attach(dataset.pttB)
```
```{r}
#Growing Tree
boost.ptt_train <- gbm(post_total_tickets~., data=dataset.pttB[train,], distribution='gaussian', n.trees=1000, interaction.depth=4)
#Can't plot tree
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
boost.ptt_pred <- predict(boost.ptt_train, dataset.pttB[-train,], n.trees=1000)
plot(boost.ptt_pred, post_total_tickets[-train])
abline(0,1)
#MSE
MSE.boost.ptt <- mean((boost.ptt_pred-post_total_tickets[-train])^2)
MSE.boost.ptt
A_methods <- rbind(A_methods, c('Boosted Tree',MSE.boost.ptt))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.boost.ptt,". Root MSE is",sqrt(MSE.boost.ptt),", indicating this model leads to test predictions within around",round(sqrt(MSE.boost.ptt),2),"total tickets purchased."))
```

#### <a id="end_B"></a>**B** Looking at Most Effective Method

```{r}
A_methods <- A_methods[-1,]
A_methods[order(A_methods[,2],decreasing = FALSE),]
Top <- A_methods[1,]
```
```{r,echo=FALSE}
print(paste("The most effective method was the",Top[1],", with",Top[2],"MSE."))
A_methods <- matrix(c("",""),
                    nrow=1,
                    ncol=2)
```

#### (Recall) Looking at distribution of test response variable

```{r}
#Creating Violin Plot
p <- ggplot(dataset.ptt[-train,], aes(y=post_total_tickets, 1))
p + geom_violin()
```

[Back to top](#top)

## <a id="begin_C"></a>C - How much money do people spend on tickets?

### Removing other response variables besides post_total_ticket_amt

```{r}
#Finding postion of desired response variable
Q <- match('post_total_ticket_amt',a)
a[Q]
#Removing all other response (post_) variables
POSTN_ptta <- POSTN[! POSTN %in% Q]
#POSTN_ptta
a[POSTN_ptta]
dataset.ptta <- d[,-POSTN_ptta]
```
```{r,results='hide',message=FALSE}
attach(dataset.ptta)
```

#### Looking at distribution of test response variable

```{r}
#Creating Violin Plot
p <- ggplot(dataset.ptta[-train,], aes(y=post_total_ticket_amt, 0))
p + geom_violin()
```

#### That's a lot of zeroes

```{r}
#Finding Number of Zeroes
O <- table(post_total_ticket_amt[-train]==0)
#O[2]
```

#### Growing Preliminary Regression Tree

```{r}
#Growing Tree
tree.ptta <- tree(post_total_ticket_amt~., dataset.ptta)
#Plotting Tree
plot(tree.ptta)
text(tree.ptta,pretty=0)
```

Estimate MSE on (extremely similar) Trained Tree
```{r}
#Growing Tree
tree.ptta_train <- tree(post_total_ticket_amt~., dataset.ptta, subset=train)
#Plotting Tree
plot(tree.ptta_train)
text(tree.ptta_train,pretty=0)
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
tree.ptta_pred <- predict(tree.ptta_train, dataset.ptta[-train,])
plot(tree.ptta_pred, post_total_ticket_amt[-train])
abline(0,1)
#MSE
MSE.ptta <- mean((tree.ptta_pred-post_total_ticket_amt[-train])^2)
MSE.ptta
A_methods <- rbind(A_methods, c("Tree",MSE.ptta))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.ptta,". Root MSE is",sqrt(MSE.ptta),", indicating this model leads to test predictions within around",round(sqrt(MSE.ptta),1),"dollars of total ticket amount."))
```

Pruning the Tree
```{r}
#Cross Validating Tree
cv.ptta_train <- cv.tree(tree.ptta_train, FUN=prune.tree)
#Finding best parameter to prune
cv.ptta_train
b <- which.min(cv.ptta_train$dev)
Best <- cv.ptta_train$size[b]
```
```{r,echo=FALSE}
print(paste("The best trees seem to be of size",cv.ptta_train$size[b],"with deviation of",cv.ptta_train$dev[b],"."))
```
```{r}
#Pruning Tree based on this
prune.ptta_train <- prune.tree(tree.ptta_train, best=Best)
#Plotting Tree
plot(prune.ptta_train)
text(prune.ptta_train,pretty=0)
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
prune.ptta_pred <- predict(prune.ptta_train, dataset.ptta[-train,])
plot(prune.ptta_pred, post_total_ticket_amt[-train])
abline(0,1)
#MSE
MSE.prune.ptta <- mean((prune.ptta_pred-post_total_ticket_amt[-train])^2)
MSE.prune.ptta
A_methods <- rbind(A_methods, c("Cross Validated Tree",MSE.prune.ptta))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.prune.ptta,". Root MSE is",sqrt(MSE.prune.ptta),", indicating this model leads to test predictions within around",round(sqrt(MSE.prune.ptta),1),"dollars of total ticket amount."))
```

#### Creating Bagged Tree

```{r}
#Creating a modified dataset - na values are not accepted in bagged trees
dataset.ptta0 <- dataset.ptta
dataset.ptta0[is.na(dataset.ptta0)] <- 0
```
```{r,results='hide',message=FALSE}
attach(dataset.ptta0)
```
```{r}
#Growing Tree
bag.ptta_train <- randomForest(post_total_ticket_amt~., data=dataset.ptta0, subset=train, mtry=ncol(dataset.ptta0)-1, ntrees=1000, importance=TRUE)
#Can't plot tree
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
bag.ptta_pred <- predict(bag.ptta_train, dataset.ptta0[-train,])
plot(bag.ptta_pred, post_total_ticket_amt[-train])
abline(0,1)
#MSE
MSE.bag.ptta <- mean((bag.ptta_pred-post_total_ticket_amt[-train])^2)
MSE.bag.ptta
A_methods <- rbind(A_methods, c("Bagged Tree",MSE.bag.ptta))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.bag.ptta,". Root MSE is",sqrt(MSE.bag.ptta),", indicating this model leads to test predictions within around",round(sqrt(MSE.bag.ptta),1),"dollars of total ticket amount."))
```

#### Looking at Predictor Importance 
```{r}
bag.I <- importance(bag.ptf_train)
bag.I <- bag.I[ order(bag.I[,3],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by error) according to this model are as follows:")
```
```{r}
bag.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
bag.I <- bag.I[ order(bag.I[,4],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by Gini index) according to this model are as follows:")
```
```{r}
bag.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
```

#### Creating Random Forest Tree

```{r}
#Growing Tree
RF.ptta_train <- randomForest(post_total_ticket_amt~., data=dataset.ptta0, subset=train, importance=TRUE)
#Can't plot tree
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
RF.ptta_pred <- predict(RF.ptta_train, dataset.ptta0[-train,])
plot(RF.ptta_pred, post_total_ticket_amt[-train])
abline(0,1)
#MSE
MSE.RF.ptta <- mean((RF.ptta_pred-post_total_ticket_amt[-train])^2)
MSE.RF.ptta
A_methods <- rbind(A_methods, c("Random Forest Tree",MSE.RF.ptta))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.bag.ptta,". Root MSE is",sqrt(MSE.RF.ptta),", indicating this model leads to test predictions within around",round(sqrt(MSE.RF.ptta),1),"dollars of total ticket amount."))
```

#### Looking at Predictor Importance 
```{r}
RF.I <- importance(RF.ptf_train)
RF.I <- RF.I[ order(RF.I[,3],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by error) according to this model are as follows:")
```
```{r}
RF.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
RF.I <- RF.I[ order(RF.I[,4],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by Gini index) according to this model are as follows:")
```
```{r}
RF.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
```

#### Creating a Boosted Tree
```{r}
#Creating a modified dataset - columns with no variation are not accepted in boosted trees
dataset.pttaB <- dataset.ptta
colnames(dataset.pttaB)[c(36,56)]
dataset.pttaB <- dataset.pttaB[,-c(36,56)]
```
```{r,results='hide',message=FALSE}
attach(dataset.pttaB)
```
```{r}
#Growing Tree
boost.ptta_train <- gbm(post_total_ticket_amt~., data=dataset.pttaB[train,], distribution='gaussian', n.trees=1000, interaction.depth=4)
#Can't plot tree
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
boost.ptta_pred <- predict(boost.ptta_train, dataset.pttaB[-train,], n.trees=1000)
plot(boost.ptta_pred, post_total_ticket_amt[-train])
abline(0,1)
#MSE
MSE.boost.ptta <- mean((boost.ptta_pred-post_total_ticket_amt[-train])^2)
MSE.boost.ptta
A_methods <- rbind(A_methods, c("Boosted Tree",MSE.boost.ptta))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.boost.ptta,". Root MSE is",sqrt(MSE.boost.ptta),", indicating this model leads to test predictions within around",round(sqrt(MSE.boost.ptta),1),"dollars of total ticket amount."))
```

#### <a id="end_C"></a>**C** Looking at Most Effective Method

```{r}
A_methods <- A_methods[-1,]
A_methods[order(A_methods[,2],decreasing = FALSE),]
Top <- A_methods[1,]
```
```{r,echo=FALSE}
print(paste("The most effective method was the",Top[1],", with",Top[2],"MSE."))
A_methods <- matrix(c("",""),
                    nrow=1,
                    ncol=2)
```

#### (Recall) Looking at distribution of test response variable

```{r}
#Creating Violin Plot
p <- ggplot(dataset.ptta[-train,], aes(y=post_total_ticket_amt, 0))
p + geom_violin()
```


[Back to top](#top)

## <a id="begin_D"></a>D - Who buys tickets at which price?

### Removing other response variables besides post_avg_ticket_price

```{r}
#Finding postion of desired response variable
Q <- match('post_avg_ticket_price',a)
a[Q]
#Removing all other response (post_) variables
POSTN_patp <- POSTN[! POSTN %in% Q]
#POSTN_patp
a[POSTN_patp]
dataset.patp <- d[,-POSTN_patp]
```
```{r,results='hide',message=FALSE}
attach(dataset.patp)
```

Looking at distribution of test response variable

```{r}
#Creating Violin Plot
p <- ggplot(dataset.patp[-train,], aes(y=post_avg_ticket_price, 0))
p + geom_violin()
```

#### That's a lot of zeroes

```{r}
#Finding Number of Zeroes
O <- table(post_avg_ticket_price[-train]==0)
#O[2]
```
```{r,echo=FALSE}
print(paste(O[2]/(O[1]+O[2]),"of the values are zeroes."))
```

#### Growing Preliminary Regression Tree

```{r}
#Growing Tree
tree.patp <- tree(post_avg_ticket_price~., dataset.patp)
#Plotting Tree
plot(tree.patp)
text(tree.patp,pretty=0)
```

Estimate MSE on (extremely similar) Trained Tree
```{r}
#Growing Tree
tree.patp_train <- tree(post_avg_ticket_price~., dataset.patp, subset=train)
#Plotting Tree
plot(tree.patp_train)
text(tree.patp_train,pretty=0)
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
tree.patp_pred <- predict(tree.patp_train, dataset.patp[-train,])
plot(tree.patp_pred, post_avg_ticket_price[-train])
abline(0,1)
#MSE
MSE.patp <- mean((tree.patp_pred-post_avg_ticket_price[-train])^2)
MSE.patp
A_methods <- rbind(A_methods, c("Tree",MSE.patp ))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.patp,". Root MSE is",sqrt(MSE.patp),", indicating this model leads to test predictions within around",round(sqrt(MSE.patp),1),"dollars of the average ticket price."))
```

Pruning the Tree
```{r}
#Cross Validating Tree
cv.patp_train <- cv.tree(tree.patp_train, FUN=prune.tree)
#Finding best parameter to prune tree
cv.patp_train
b <- which.min(cv.patp_train$dev)
Best <- cv.patp_train$size[b]
```
```{r,echo=FALSE}
print(paste("The best trees seem to be of size",cv.patp_train$size[b],"with deviation of",cv.patp_train$dev[b],"."))
```
```{r}
#Pruning Tree based on this
prune.patp_train <- prune.tree(tree.patp_train, best=Best)
#Plotting Tree
plot(prune.patp_train)
text(prune.patp_train,pretty=0)
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
prune.patp_pred <- predict(prune.patp_train, dataset.patp[-train,])
plot(prune.patp_pred, post_avg_ticket_price[-train])
abline(0,1)
#MSE
MSE.prune.patp <- mean((prune.patp_pred-post_avg_ticket_price[-train])^2)
MSE.prune.patp
A_methods <- rbind(A_methods, c("Cross Validated Tree",MSE.prune.patp))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.prune.patp,". Root MSE is",sqrt(MSE.prune.patp),", indicating this model leads to test predictions within around",round(sqrt(MSE.prune.patp),1),"dollars of the average ticket price."))
```

#### Creating Bagged Tree

```{r}
#Creating a modified dataset - na values are not accepted in bagged trees
dataset.patp0 <- dataset.patp
dataset.patp0[is.na(dataset.patp0)] <- 0
```
```{r,results='hide',message=FALSE}
attach(dataset.patp0)
```
```{r}
#Growing Tree
bag.patp_train <- randomForest(post_avg_ticket_price~., data=dataset.patp0, subset=train, mtry=ncol(dataset.patp0)-1, ntrees=1000, importance=TRUE)
#Can't plot tree
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
bag.patp_pred <- predict(bag.patp_train, dataset.patp0[-train,])
plot(bag.patp_pred, post_avg_ticket_price[-train])
abline(0,1)
#MSE
MSE.bag.patp <- mean((bag.patp_pred-post_avg_ticket_price[-train])^2)
MSE.bag.patp
A_methods <- rbind(A_methods, c("Bagged Tree",MSE.bag.patp))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.bag.patp,". Root MSE is",sqrt(MSE.bag.patp),", indicating this model leads to test predictions within around",round(sqrt(MSE.bag.patp),1),"dollars of the average ticket price."))
```

#### Looking at Predictor Importance 
```{r}
bag.I <- importance(bag.ptf_train)
bag.I <- bag.I[ order(bag.I[,3],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by error) according to this model are as follows:")
```
```{r}
bag.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
bag.I <- bag.I[ order(bag.I[,4],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by Gini index) according to this model are as follows:")
```
```{r}
bag.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
```

#### Creating Random Forest Tree

```{r}
#Growing Tree
RF.patp_train <- randomForest(post_avg_ticket_price~., data=dataset.patp0, subset=train, importance=TRUE)
#Can't plot tree
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
RF.patp_pred <- predict(RF.patp_train, dataset.patp0[-train,])
plot(RF.patp_pred, post_avg_ticket_price[-train])
abline(0,1)
#MSE
MSE.RF.patp <- mean((RF.patp_pred-post_avg_ticket_price[-train])^2)
MSE.RF.patp
A_methods <- rbind(A_methods, c("Random Forest Tree",MSE.RF.patp))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.bag.patp,". Root MSE is",sqrt(MSE.RF.patp),", indicating this model leads to test predictions within around",round(sqrt(MSE.RF.patp),1),"dollars of the average ticket price."))
```

#### Looking at Predictor Importance 
```{r}
RF.I <- importance(RF.ptf_train)
RF.I <- RF.I[ order(RF.I[,3],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by error) according to this model are as follows:")
```
```{r}
RF.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
RF.I <- RF.I[ order(RF.I[,4],decreasing=TRUE), ]
```
```{r,echo=FALSE}
print("The fifteen most important predictors (by Gini index) according to this model are as follows:")
```
```{r}
RF.I[1:15,] #includes variable 'tenure' - is this to be removed from this dataset as well?
```

#### Creating a Boosted Tree
```{r}
#Creating a modified dataset - columns with no variation are not accepted in boosted trees
dataset.patpB <- dataset.patp
colnames(dataset.patpB)[c(36,56)]
dataset.patpB <- dataset.patpB[,-c(36,56)]
```
```{r,results='hide',message=FALSE}
attach(dataset.patpB)
```
```{r}
#Growing Tree
boost.patp_train <- gbm(post_avg_ticket_price~., data=dataset.patpB[train,], distribution='gaussian', n.trees=1000, interaction.depth=4)
#Can't plot tree
```

#### Calculating, Plotting, and Recording (Mean Squared) Error

```{r}
#Fitting model on test set
boost.patp_pred <- predict(boost.patp_train, dataset.patpB[-train,], n.trees=1000)
plot(boost.patp_pred, post_avg_ticket_price[-train])
abline(0,1)
#MSE
MSE.boost.patp <- mean((boost.patp_pred-post_avg_ticket_price[-train])^2)
MSE.boost.patp
A_methods <- rbind(A_methods, c("Boosted Tree",MSE.boost.patp))
```
```{r,echo=FALSE}
print(paste("Test MSE is",MSE.boost.patp,". Root MSE is",sqrt(MSE.boost.patp),", indicating this model leads to test predictions within around",round(sqrt(MSE.boost.patp),1),"dollars of the average ticket price."))
```

#### <a id="end_D"></a>**D** Looking at Most Effective Method
```{r}
A_methods <- A_methods[-1,]
A_methods[order(A_methods[,2],decreasing = FALSE),]
Top <- A_methods[1,]
```
```{r,echo=FALSE}
print(paste("The most effective method was the",Top[1],", with",Top[2],"MSE."))
A_methods <- matrix(c("",""),
                    nrow=1,
                    ncol=2)
```
[Back to top](#top)